{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ad3de52-82e3-47ac-b54a-081c560cb49f",
   "metadata": {},
   "source": [
    "## Setting up the Chat Completion API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8b5e78-e258-465d-9c29-692d1dc7bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_completion_request(messages, tools=None, tool_choice=None, model):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=tool_choice,\n",
    "            temperature=0.2,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb5ea3b-a9a8-49c4-a8ae-bff03b148ff4",
   "metadata": {},
   "source": [
    "## Function description of get_wiki\n",
    "This is required in order for the GPT to identify mathematical terms and send them back in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fd8348-e0bb-4279-a4d6-ca0e4c1ffced",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_RAG = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_wiki\",\n",
    "            \"description\": \"Retrieve contextual information of given mathematical terminology from English and Swedish Wikipedia.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"terms\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"string\",\n",
    "                        },\n",
    "                        \"description\": \"List of mathematical terminology to check their context on Wikipedia before translating them to Swedish.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"terms\"],\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579cd24d-6957-4f59-b9c6-8916871f3586",
   "metadata": {},
   "source": [
    "## Helper functions for get_wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e0a1aa-d456-43e1-b3b3-bf586a14fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # Default to noun if POS tag is unknown\n",
    "\n",
    "def save_embedding_to_csv(word, embedding):\n",
    "    try:\n",
    "        df = pd.read_csv('saved_embeddings.csv')\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(columns=['word', 'embedding'])\n",
    "\n",
    "    new_entry = pd.DataFrame({'word': [word], 'embedding': [embedding]})\n",
    "    df = pd.concat([df, new_entry], ignore_index=True)\n",
    "    df.to_csv('saved_embeddings.csv', index=False)\n",
    "\n",
    "def load_embedding_from_csv(word):\n",
    "    try:\n",
    "        df = pd.read_csv('saved_embeddings.csv')\n",
    "        df['embedding'] = df['embedding'].apply(eval).apply(np.array)  # Convert strings to arrays\n",
    "        embedding = df.loc[df['word'] == word, 'embedding'].values\n",
    "        if len(embedding) > 0:\n",
    "            return embedding[0]\n",
    "        else:\n",
    "            return None\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        return client.embeddings.create(input = [text], model=model).data[0].embedding  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4ee51f-9c9f-4fae-a9d6-35fb4e94948d",
   "metadata": {},
   "source": [
    "## get_wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249d0f72-f089-4294-a990-d9b00c814741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wiki(words):\n",
    "    def cosine(content_emb, word_emb):\n",
    "        return np.dot(content_emb, word_emb) / (norm(word_emb) * norm(content_emb))\n",
    "    df = pd.read_csv('wikipedia_content.csv')\n",
    "    df['English embeddings'] = df['English embeddings'].apply(eval).apply(np.array)  \n",
    "\n",
    "    results = {}\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    threshold = 0.39\n",
    "    if isinstance(words, str):\n",
    "        words = [words]\n",
    "        \n",
    "    for word in words:    \n",
    "        word = lemmatizer.lemmatize(word.lower(), get_wordnet_pos(word.lower()))\n",
    "        match = df[df['English title'].str.lower() == word.lower()]\n",
    "        match2 = df[df['English section title'].str.lower() == word.lower()]\n",
    "        \n",
    "        if not match.empty:\n",
    "            sv_content = match.iloc[0]['Swedish section content']\n",
    "            en_content = match.iloc[0]['English section content']\n",
    "            results[word] = {\n",
    "                'sv_content': sv_content,\n",
    "                'en_content': en_content\n",
    "            }\n",
    "\n",
    "        elif not match2.empty: \n",
    "            sv_content = match2.iloc[0]['Swedish section content']\n",
    "            en_content = match2.iloc[0]['English section content']\n",
    "            results[word] = {\n",
    "                'sv_content': sv_content,\n",
    "                'en_content': en_content\n",
    "            }\n",
    "            \n",
    "        else:\n",
    "            word_emb = load_embedding_from_csv(word)\n",
    "            if word_emb is None:\n",
    "                word_emb = get_embedding(word)\n",
    "                save_embedding_to_csv(word, word_emb)\n",
    "            df['distance'] = df['English embeddings'].apply(lambda x: cosine(x, word_emb))\n",
    "            df.sort_values('distance', ascending=False, inplace=True)\n",
    "            value = df['distance'].iloc[0]\n",
    "            content = df['English section content'].iloc[0]\n",
    "    \n",
    "            if value >= threshold:  \n",
    "                sv_content = df['Swedish section content'].iloc[0] \n",
    "                en_content = df['English section content'].iloc[0]\n",
    "                results[word] = {\n",
    "                    'sv_content': sv_content,\n",
    "                    'en_content': en_content\n",
    "                }\n",
    "            else:\n",
    "                results[word] = None\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713bea8b-1dc0-482f-ac40-1701445dcfa7",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c46b0e5b-6fe9-4a3b-bbf2-885b7dcb36cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_final_translation(terms):\n",
    "    final_translation_parts = []\n",
    "    for term, content in terms.items():\n",
    "        if content:\n",
    "            term_sentence = f\"{term}: {content['sv_content']}: {content['en_content']}\"\n",
    "            final_translation_parts.append(term_sentence + \"\\n\\n\")\n",
    "        else:\n",
    "            term_sentence = f\"{term}: 'None'.\"\n",
    "            final_translation_parts.append(term_sentence + \"\\n\\n\")\n",
    "    final_translation_parts.append(\"Don't wait for context for terminology that have value None.\")\n",
    "    final_translation = \" \".join(final_translation_parts)\n",
    "    return final_translation\n",
    "\n",
    "def RAG(sentence):\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"system\", \n",
    "                     \"content\": \"Your sole task is to translate a given English sentence into Swedish. Ensure the use of correct mathematical terminology and make sure the sentence sounds natural to a Swedish student. Careful attention should be paid to mathematical terminology, avoiding assumptions about translations. Instead, list all mathematical terms requiring verification, and corresponding Wikipedia content in both Swedish and English will be provided to ensure accuracy. If the context for terminology is unavailable or unclear, translation should proceed accurately by verifying common practices in Sweden.\"})\n",
    "    messages.append({\"role\": \"user\", \n",
    "                    \"content\": f\"Translate the following content to Swedish. Keep any LaTeX expressions and numbers as they are. Output only the translated sentence: {sentence}\"})\n",
    "\n",
    "\n",
    "    chat_response = chat_completion_request(messages, tools=tools_RAG, tool_choice=\"auto\", model='gpt-4o')\n",
    "    assistant_message = chat_response.choices[0].message\n",
    "    if assistant_message.tool_calls:\n",
    "        function_name = assistant_message.tool_calls[0].function.name\n",
    "        arguments_value = json.loads(assistant_message.tool_calls[0].function.arguments) # <--- this is where GPT identified mathematical terms\n",
    "        terms = arguments_value.get(\"terms\")\n",
    "        if terms:\n",
    "            pass\n",
    "        else:\n",
    "            return \"ERROR\"\n",
    "        wikipedia_content = get_wiki(terms) # <--- this is where the retrival happens\n",
    "        if wikipedia_content:\n",
    "            final_translation_content = construct_final_translation(wikipedia_content) \n",
    "            final_translation = f\"If possible and relevant, refine the translation with the help of the provided content. Output only the translated sentence: {final_translation_content}.\"                \n",
    "            messages.append({\"role\": \"assistant\", \"content\": final_translation})\n",
    "            \n",
    "    chat_response = chat_completion_request(messages, tools=tools_RAG, tool_choice=\"none\", model='gpt-4o')\n",
    "    assistant_message = chat_response.choices[0].message\n",
    "    return assistant_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c51f4c-9bac-4572-b894-6c9cf412f02b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
